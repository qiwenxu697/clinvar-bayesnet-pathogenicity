# -*- coding: utf-8 -*-
"""data_processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/127FyBq0bAURklNT_J-BmtNvBR3f0siMI

### Bayesian Network for Mutation Impact Prediction

**Course**: CSE 150A/250A \
**Team Name:** SeqPredict \
**Team Members:** Qiwen Xu, Michael Kroyan, Janice Rincon, Vibusha Vadivel, Jiya Makhija
"""

pip install pgmpy

import pandas as pd
import re

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

df = pd.read_csv('/content/drive/MyDrive/cse150a_finalproject/variant_summary.txt.gz', sep='\t', compression='gzip')

print(f"Total variants: {len(df)}")

df.head()

"""### Feature Engineering"""

df['ClinSigSimple'].unique()

"""
ClinSigSimple          integer, 0 = no current value of Likely pathogenic; Pathogenic; Likely pathogenic, low penetrance;
                                    Pathogenic, low penetrance; Likely risk allele; or Risk allele
                                1 = at least one current record submitted with an interpretation of Likely pathogenic; Pathogenic;
                                    Likely pathogenic, low penetrance; Pathogenic, low penetrance; Likely risk allele;
                                    or Risk allele (independent of whether that record includes assertion criteria and evidence).
                               -1 = no values for clinical significance at all for this variant or set of variants; used for
                                    the "included" variants that are only in ClinVar because they are included in a
                                    haplotype or genotype with an interpretation


Removing -1 as a value since ClinVar documentation says it's for variants
that don't have pathogenicity classifications and have no clinical signficance
"""

df = df[df['ClinSigSimple'].isin([0, 1])].copy()

# remove missing data
df = df.dropna(subset=['Type', 'Chromosome', 'Start', 'Stop', 'GeneSymbol'])

df['Type'].unique()

# per our project plan
features = pd.DataFrame()


# feature 1 - VariantType
variant_mapping = {
    'single nucleotide variant': 'SNV',
    'Deletion': 'Deletion',
    'Insertion': 'Indel',
    'Indel': 'Indel',
    'Duplication': 'Indel',
    'copy number gain': 'CNV',
    'copy number loss': 'CNV',
    'Microsatellite': 'Other',
    'Variation': 'Other',
    'Complex': 'Other',
    'Translocation': 'Other',
    'Inversion': 'Other',
    'fusion': 'Other',
    'protein only': 'Other',
    'Tandem duplication': 'Other'
}

features['VariantType'] = df['Type'].map(variant_mapping)

# feature 2 - LengthChange_bin
"""Indels = Insertions + Deletions
Insertions: Extra DNA gets added
Deletions: DNA gets removed

https://pmc.ncbi.nlm.nih.gov/articles/PMC5570956/#Sec1 :
"A rate of 2.94 indels (1-20 bp) and
0.16 structural variants (>20 bp) per generation was estimated based on whole genome sequencing of 250 families"

so single nucleotide variant is 1 small indels (2-20) and large >20 - so large indels are more likely to cause disease because rare?
"""

variant_length = df['Stop'] - df['Start'] + 1

features['LengthChange_bin'] = pd.cut(variant_length, bins=[-1, 1, 20, float('inf')], labels=['SNV', 'small_indel', 'large_indel'])

# feature 3 - Frameshift
"""removing indels not divisible by 3 - because they cause frameshifts

NOTE: this is an approximation because ClinVar provides genomic alleles, not transcript-specific coding alleles

"""
ref_len = df["ReferenceAllele"].astype(str).str.len()
alt_len = df["AlternateAllele"].astype(str).str.len()

length_change = alt_len - ref_len   # insertion = positive, deletion = negative

frameshift = (length_change % 3 != 0) & df["Type"].isin(["Deletion", "Insertion", "Indel"])
features['Frameshift'] = frameshift.astype(int)

# feature 4 - StopGain
"""StopGain is caused by a single DNA letter change that accidentally creates a STOP signal
NOTE: this is an approximation because True stop-gain classification depends on transcript-specific coding
context, which is not available in our dataset.

Approximation stop-gain mutations by parsing the HGVS protein notation (like '(p.Gln232Ter)', '(p.Arg33*)')
or text descriptions such as 'nonsense mutation' or 'stop-gain'"""

stop_pattern = re.compile(
    r"\(p\.[A-Za-z]{3}\d+(ter|\*)\)", re.IGNORECASE
)

def is_stopgain(name):
    if pd.isna(name):
        return False
    s = str(name)

    # protein-based stop-gain
    if stop_pattern.search(s):
        return True

    # text-based descriptions
    s_low = s.lower()
    text_stop_indicators = ['nonsense mutation', 'stop-gain', 'stop_gain','stopgained']
    # 1 if variant creates a premature STOP codon, 0 if not
    return any(indicator in s_low for indicator in text_stop_indicators)

features['StopGain'] = df['Name'].apply(is_stopgain).astype(int)

df['GeneSymbol'].value_counts()

# feature 5 - GeneGroup
gene_mapping = {
    'TTN': 'structural',           # Titin - structural muscle protein
    'BRCA2': 'tumor_suppressor',
    'ATM': 'tumor_suppressor',
    'APC': 'tumor_suppressor',
    'NF1': 'tumor_suppressor',    # Neurofibromatosis

    # Other common tumor suppressors
    'BRCA1': 'tumor_suppressor', 'TP53': 'tumor_suppressor',
    'PTEN': 'tumor_suppressor', 'VHL': 'tumor_suppressor',
    'RB1': 'tumor_suppressor', 'MLH1': 'tumor_suppressor',
    'MSH2': 'tumor_suppressor', 'MSH6': 'tumor_suppressor',
    'PMS2': 'tumor_suppressor', 'PALB2': 'tumor_suppressor',

    # Metabolism
    'APOE': 'metabolism', 'LDLR': 'metabolism', 'GBA': 'metabolism',
    'PAH': 'metabolism', 'HFE': 'metabolism',

    # Ion channels
    'CFTR': 'channel_protein', 'SCN5A': 'channel_protein',
    'SCN1A': 'channel_protein', 'KCNQ1': 'channel_protein',

    # Structural
    'FBN1': 'structural', 'COL1A1': 'structural', 'COL1A2': 'structural',
    'MYH7': 'structural', 'MYBPC3': 'structural',

    # DNA repair
    'RNASEL': 'dna_repair', 'MUTYH': 'dna_repair'
}

features['GeneGroup'] = df['GeneSymbol'].map(gene_mapping).fillna('other')

df['Chromosome'].value_counts()

# feature 6 - Chromosome_clean
def clean_chromosome(chrom_value):
    chrom_str = str(chrom_value).strip()

    if chrom_str in ['X', 'Y']:
        return 'sex_chr'
    elif chrom_str == 'MT':
        return 'mitochondrial'
    # missing/unknown
    elif chrom_str in ['na', 'Un', 'nan']:
        return 'unknown'
    # everything else is autosome from 1-22 (autosomes are regular chromosomes)
    else:
        return 'autosome'

features['Chromosome_clean'] = df['Chromosome'].apply(clean_chromosome)

print(features['Chromosome_clean'].value_counts())

# feature 7 - PositionBin
"""some regions are gene-rich vs gene-poor - may influence the pathogenicity"""
features['PositionBin'] = pd.qcut(df['Start'], q=3,
                                 labels=['low', 'mid', 'high'],
                                 duplicates='drop')

# feature 8 - PhenotypeCount_bin
"""variants linked to many diseases are more likely to be genuinely pathogenic

none: about 3000 variants (0 diseases)
few: about 7.7 million variants (1-2 diseases)
moderate: about 134,000 variants (3-5 diseases)
many: about 3,000 variants (6+ diseases)

"""

def count_diseases(pheno_list):
    if pd.isna(pheno_list) or pheno_list == '-':
        return 0
    return len(str(pheno_list).split(';'))

disease_counts = df['PhenotypeList'].apply(count_diseases)
features['PhenotypeCount_bin'] = pd.cut(disease_counts,
                                        bins=[-1, 0, 2, 5, float('inf')],
                                        labels=['none', 'few', 'moderate', 'many'])

print(disease_counts.value_counts().sort_index())

# feature 9 - ClinSigSimple_num (target variable)
"""What our BN will predict - Binary classification target: 0=benign, 1=pathogenic"""
features['ClinSigSimple_num'] = df['ClinSigSimple']

target_counts = features['ClinSigSimple_num'].value_counts()
target_counts

print(features['ClinSigSimple_num'].value_counts(normalize=True) * 100)

features.to_csv('features_clean.csv', index=False)

"""### Model creation"""

# load cleaned/processed features
data = pd.read_csv('/content/drive/MyDrive/cse150a_finalproject/features_clean.csv')

len(data)

data.head()

data_clean = data.drop(columns=["PhenotypeCount_bin","StopGain", "Frameshift", "LengthChange_bin", "PositionBin"])

data_clean.head()

data_clean["ClinSigSimple_num"].value_counts(normalize=True)

from sklearn.model_selection import train_test_split

# split data into train-test
train_df, test_df = train_test_split(data_clean, test_size=0.2, random_state=42)

# learn the DAG from train with HillClimbSearch
from pgmpy.models import DiscreteBayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.estimators import HillClimbSearch, BIC, ExpertKnowledge
from pgmpy.inference import VariableElimination
from pgmpy.estimators import MaximumLikelihoodEstimator
from sklearn.metrics import accuracy_score
import numpy as np

TARGET = "ClinSigSimple_num"
feature_cols = [c for c in data_clean.columns if c != TARGET]

# Forbid edges going *out* of the label
forbidden = [(TARGET, f) for f in feature_cols]

expert_knowledge = ExpertKnowledge(
    forbidden_edges=forbidden
)

hc = HillClimbSearch(train_df)

dag = hc.estimate(
   scoring_method=BIC(train_df),
   max_indegree=4,          # limit parents per node
   expert_knowledge=expert_knowledge,
)

print("Learned edges:")
print(list(dag.edges()))

# build a BayesianNetwork and learn the Conditional Probability Distribitions (CPDs) -> MLE

# build the BN using the learned DAG edges
model = DiscreteBayesianNetwork(dag.edges())

# fit CPDs using MLE
model.fit(train_df, estimator=MaximumLikelihoodEstimator)

# inspect learnt CPDs
for cpd in model.get_cpds():
  print(cpd)

# Use inference for prediction on test set
from pgmpy.inference import VariableElimination
import numpy as np

infer = VariableElimination(model)

TARGET = "ClinSigSimple_num"
feature_cols = [c for c in data_clean.columns if c != TARGET]

y_true = []
y_pred = []
y_proba = []

for _, row in test_df.iterrows():
    # evidence excludes the target
    evidence = {col: row[col] for col in feature_cols}

    # BN inference
    q = infer.query(variables=[TARGET], evidence=evidence, show_progress=False)

    # Probability of class 1 (pathogenic)
    prob_1 = q.values[1]     # q.values is array: [P(0), P(1)]
    y_proba.append(prob_1)

    # Argmax predicted class
    idx = q.values.argmax()  # returns index 0 or 1
    pred_state = q.state_names[TARGET][idx]
    y_pred.append(pred_state)

    # True label
    y_true.append(row[TARGET])

# Convert to arrays for sklearn
y_true = np.array(y_true, dtype=int)
y_pred = np.array(y_pred, dtype=int)
y_proba = np.array(y_proba, dtype=float)

# TESTING METRICS
from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score

# Compute accuracy
accuracy = np.mean(np.array(y_true) == np.array(y_pred))
print("Test accuracy:", accuracy)

# Classification report (precision/recall/F1)
print("Classification: ")
print(classification_report(y_true, y_pred, digits=4))

# ROC AUC
roc_auc = roc_auc_score(y_true, y_proba)
print(f"ROC AUC: {roc_auc:.4f}")

# Precisionâ€“Recall curve
prec, rec, thresholds = precision_recall_curve(y_true, y_proba)

# Average precision (PR-AUC)
ap = average_precision_score(y_true, y_proba)
print(f"Average Precision (PR AUC): {ap:.4f}")